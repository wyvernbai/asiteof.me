Cuda-convnet is a High-performance C++/CUDA implementation of convolutional neural networks. Here is the [Project Link](https://code.google.com/p/cuda-convnet).

Cuda-convnet is built for Linux by default. There is no details description or test about compiling the project on Windows. It is said that's possible but not easy to compile and use this code on Windows. Here is a solution for Visual Studio 2010 tested on my local windows pc with GeFore GTX690.

#Required Software Installed#
Before compile Cuda-convnet for Windows, you should make sure you have:

1. Visual Studio 2010/2012
2. Python2.7 with numpy
3. CUDA5 SDK
4. [LIBS.zip](https://www.dropbox.com/s/obyzzcankkknjip/LIBS.zip) (This is a zip file including many dll, lib and head file you may need. such as openBLAS and pthread-x64)

#Create VC++ Solution#

1. Download the VS project file [here](http://code.google.com/p/cuda-convnet/downloads/detail?name=cuda-convnet-vs-proj.zip), zipped it; Copy the all cuda-convnet's source code into the zipped project's folder. 
2. Make sure the configuration type is DLL. **Property -> Configuration Properties -> General  -> Configuration Type** select **Dynamic Library(.dll)**
3. Replace `cutil_inline.h` with `helper_cuda.h` in all C++ files
4. Replace `cutilCheckMsg ` with `getLastCudaError ` in all C++ files
5. Add `#include <helper_image.h>` into *include/cudaconv2/conv_util.cuh* and *include/nvmatrix/nvmatrix.cuh*. This is for MIN and MAX macros.
6. Modify Line31 in *include/common/matrixh* as below (add `#define NUMPY_INTERFACE`):<pre>
#define NUMPY\_INTERFACE
#ifdef NUMPY\_INTERFACE
#include \<Python.h\>
#include \<arrayobject.h\>
#endif
</pre>
7. Add `#include <Python.h>` into *include/neuron.cuh*
8. Add `#define cutGetMaxGflopsDeviceId() gpuGetMaxGflopsDeviceId()` into *src/convnet.cu*
9. In my solution, I use cblas.h instead of MKL. So **OpenBLAS** is needed. You can [download and compile it for VS2010/2012](https://github.com/xianyi/OpenBLAS/wiki/How-to-use-OpenBLAS-in-Microsoft-Visual-Studio) by MinGW manually or Just use the .dll, .lib and .h file in LIBS.zip
10. Replace the dependency on pthreads with [pthreads-win32](ftp://sourceware.org/pub/pthreads-win32/pthreads-w32-2-8-0-release.exe) or Just use the .dll, .lib and .h file in LIBS.zip.
11. **Property -> Configuration Properties -> C/C++  -> General -> Additional Include Directories** may be similar with mine:<pre>C:\Python27\Lib\site-packages\numpy\core\include\numpy;C:\Python27\include;D:\v-yabai\LIBS\Pre-built.2\include;D:\v-yabai\LIBS\include;C:\ProgramData\NVIDIA Corporation\CUDA Samples\v5.0\common\inc;D:\v-yabai\DNN\cuda-convnet-vs-proj\include\nvmatrix;D:\v-yabai\DNN\cuda-convnet-vs-proj\include\cudaconv2;D:\v-yabai\DNN\cuda-convnet-vs-proj\include\common;D:\v-yabai\DNN\cuda-convnet-vs-proj\include;%(AdditionalIncludeDirectories);$(CudaToolkitIncludeDir)</pre>
12. **Property -> Configuration Properties ->Linker  -> General -> Additional Library Directories** may be similar with mine:<pre>%(AdditionalLibraryDirectories);$(CudaToolkitLibDir)</pre>
13. **Property -> Configuration Properties ->Linker  -> Input-> Additional Dependencies** may be similar with mine:<pre>C:\Python27\libs\python27.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v5.0\lib\x64\cublas.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v5.0\lib\x64\cudart.lib;D:\v-yabai\LIBS\libopenblas.lib;D:\v-yabai\LIBS\pthreadVC2_x64.lib;%(AdditionalDependencies)</pre>
[comment]:14. Add `MS_NO_COREDLL` and `Py_NO_ENABLE_SHARED` in **Configuration Properties->C/C++->Preprocessor->Preprocessor Definitions** to avoid requiring 'python27_d.lib'
15. Build for X64 and Enjoy. (TIPS: use [Dependency Walker](http://www.dependencywalker.com/) to find the dlls you need, and puts them into vs2010/2012 build output folder)