Using the maximum likelihood estimates for transitions and emissions, implement the Viterbi algorithm to compute arg\_y1...yn max p(x\_1...x\_n, y\_1...y\_n)

I improved my model by split rare word into 4 parts:

* all capitalized word;
* all word whose first letter is capitalized, and others is non-capitalized letter;
* all words that contain only capital letters and dots;
* all words that consists only of numerals.

---

Run the program with command:

```
Command: ruby ner.rb ner_train.dat ner_dev.dat
Output: prediction file "ner_dev_processed.hmmprediction"
```

this program will create temp file ner\_train\_processed.dat(replaced rare words in ner\_train.dat) and ner\_processed.count(counts file create by count\_freq.py based on ner\_train\_processed.dat).

then, run the eval script:

```
Command: python eval_ne_tagger.py ner_dev.key ner_dev_processed.hmmprediction
```
Here is the output:

```
  Found 6357 NEs. Expected 5931 NEs; Correct: 3579.

            precision  recall    F1-Score
     Total:  0.680487 0.677963  0.679223
     PER:  0.745192 0.758977  0.752022
     ORG:  0.447526 0.615097  0.518099
     LOC:  0.823378 0.699019  0.756119
     MISC:   0.812793 0.565689  0.667093
```
---
[Fork On GitHub](https://github.com/wyvernbai/NLP_Tools/tree/master/NER)